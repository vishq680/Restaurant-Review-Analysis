{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bbb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06be2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review  Liked\n",
      "0                             Wow... Loved this place.      1\n",
      "1                                   Crust is not good.      0\n",
      "2            Not tasty and the texture was just nasty.      0\n",
      "3    Stopped by during the late May bank holiday of...      1\n",
      "4    The selection on the menu was great and so wer...      1\n",
      "..                                                 ...    ...\n",
      "995  I think food should have flavor and texture an...      0\n",
      "996                           Appetite instantly gone.      0\n",
      "997  Overall I was not impressed and would not go b...      0\n",
      "998  The whole experience was underwhelming, and I ...      0\n",
      "999  Then, as if I hadn't wasted enough of my life ...      0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7c3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['Review','Liked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38986af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "dataset['Review'] = dataset['Review'].apply(lambda x: x.lower())\n",
    "dataset['Review'] = dataset['Review'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(dataset[ dataset['Liked'] == 1].size)\n",
    "print(dataset[ dataset['Liked'] == 0].size)\n",
    "\n",
    "for idx,row in dataset.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(dataset['Review'].values)\n",
    "X = tokenizer.texts_to_sequences(dataset['Review'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c05402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 256)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               355152    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 867,546\n",
      "Trainable params: 867,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 256\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c4f0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 32) (670, 2)\n",
      "(330, 32) (330, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(dataset['Liked']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 123)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb56b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 - 26s - loss: 0.6868 - accuracy: 0.5672\n",
      "Epoch 2/10\n",
      "42/42 - 4s - loss: 0.5156 - accuracy: 0.7910\n",
      "Epoch 3/10\n",
      "42/42 - 3s - loss: 0.2501 - accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "42/42 - 4s - loss: 0.1203 - accuracy: 0.9567\n",
      "Epoch 5/10\n",
      "42/42 - 4s - loss: 0.1177 - accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "42/42 - 4s - loss: 0.0422 - accuracy: 0.9925\n",
      "Epoch 7/10\n",
      "42/42 - 3s - loss: 0.0246 - accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "42/42 - 4s - loss: 0.0119 - accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "42/42 - 3s - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "42/42 - 3s - loss: 0.0034 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb6b63ba30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5acc9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 1s - loss: 0.7812 - accuracy: 0.7923\n",
      "score: 0.78\n",
      "acc: 0.79\n"
     ]
    }
   ],
   "source": [
    "validation_size = 200\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
